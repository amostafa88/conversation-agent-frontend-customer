<!DOCTYPE html>
<html lang="en">

<head>
    <!-- <script defer src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1/dist/face-api.min.js"></script> -->
    <script defer src="face-api.min.js"></script>

    <style>
        body {
            padding: 0;
            margin: 0;
            width: 100vw;
            height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }

        canvas {
            position: absolute;
            transform: translateZ(0);
            /* Enable GPU acceleration */
        }



        select {
            font-size: 15px;
            background-color: purple;
            color: white;
            padding: 5px;
            border: none;
            border-radius: 5px;
            margin-bottom: 10px;
            z-index: 10;
            position: relative;
        }
    </style>
</head>

<body>

    <select id="cameraSelect">
        <option value="user">Front Camera</option>
        <option value="environment">Back Camera</option>
    </select>
    <video id="video" width="300" height="214" autoplay playsinline></video>



    <script>
        document.addEventListener("DOMContentLoaded", () => {
            const video = document.getElementById("video");
            const cameraSelect = document.getElementById("cameraSelect");
            let currentStream = null;



            Promise.all([
                // faceapi.nets.ssdMobilenetv1.loadFromUri("https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights"),
                // faceapi.nets.faceRecognitionNet.loadFromUri("https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights"),
                // faceapi.nets.faceLandmark68Net.loadFromUri("https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights")
                faceapi.nets.ssdMobilenetv1.loadFromUri("/models"),
                faceapi.nets.faceRecognitionNet.loadFromUri("/models"),
                faceapi.nets.faceLandmark68Net.loadFromUri("/models"),

            ]).then(() => {
                console.log("Models Loaded Successfully!");
                startWebcam("environment"); // Default to back camera

            }).catch(err => console.error("Error loading models:", err));


            cameraSelect.addEventListener("change", () => {
                startWebcam(cameraSelect.value);
                console.log(cameraSelect.value);

            });


            function startWebcam(facingMode) {
                if (currentStream) {
                    currentStream.getTracks().forEach(track => track.stop());
                }

                navigator.mediaDevices.enumerateDevices()
                    .then(devices => {
                        const videoDevices = devices.filter(device => device.kind === "videoinput");

                        console.log("Available video devices:", videoDevices);

                        let selectedDeviceId = videoDevices[0]?.deviceId; // Default to first camera

                        if (facingMode === "environment") {
                            const backCamera = videoDevices.find(device =>
                                device.label.toLowerCase().includes("back") || device.label.toLowerCase().includes("rear")
                            );
                            if (backCamera) {
                                selectedDeviceId = backCamera.deviceId;
                            }
                        }

                        console.log("Selected device ID:", selectedDeviceId);

                        return navigator.mediaDevices.getUserMedia({
                            video: {
                                deviceId: selectedDeviceId ? { exact: selectedDeviceId } : undefined,
                                frameRate: { ideal: 15 }
                            }
                        });
                    })
                    .then((stream) => {
                        currentStream = stream;
                        video.srcObject = stream;
                    })
                    .catch((error) => {
                        console.error("Error accessing the camera: ", error);
                    });
            }




            let imageData = [];

            function getLabeledFaceDescriptions() {

                console.log("label:");
                let label1 = "";


                console.log(label1);



                const labels = "[ahmed, malek]";

                const images = "[ahmed.png, malek.png]";

                const groups = "[Family, Friends]";



                console.log("Labels >:", labels);
                console.log("Images >:", images);
                console.log("Groups >:", groups);

                const labelArray = labels.split(",").map(label => label.replace(/[\[\]]/g, "").trim());
                const imageArray = images.split(",");
                const groupArray = groups.split(",").map(group => group.replace(/[\[\]]/g, "").trim());

                imageData = labelArray.map((label, index) => ({
                    label: label.replace(/[\[\]]/g, "").trim(),
                    imageUrl: imageArray[index] ? `${imageArray[index].replace(/[\[\]]/g, "").trim()}` : "",
                    group: groupArray[index] || "Unknown"
                }));

                console.log("Labels:", labelArray);
                console.log("Images:", imageData);
                console.log("Groups:", groupArray);

                return Promise.all(
                    labelArray.map(async (label, index) => {
                        const descriptions = [];
                        const filteredImages = imageData.filter(img => img.label === label);
                        for (let i = 0; i < filteredImages.length; i++) {
                            const img = await faceapi.fetchImage(filteredImages[i].imageUrl);
                            const detections = await faceapi
                                .detectSingleFace(img, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.6 }))
                                .withFaceLandmarks()
                                .withFaceDescriptor();
                            if (detections) {
                                descriptions.push(detections.descriptor);
                            }
                        }
                        return descriptions.length > 0 ? new faceapi.LabeledFaceDescriptors(label, descriptions) : null;
                    })
                ).then(results => results.filter(res => res !== null));
            }



            video.addEventListener("play", async () => {
                // Remove any existing canvas
                const existingCanvas = document.querySelector("canvas");
                if (existingCanvas) {
                    existingCanvas.remove();
                }

                const labeledFaceDescriptors = await getLabeledFaceDescriptions();
                const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, 0.5);

                const canvas = faceapi.createCanvasFromMedia(video);
                document.body.append(canvas);
                const displaySize = { width: video.width, height: video.height };
                faceapi.matchDimensions(canvas, displaySize);

                let boxes = [];
                setInterval(async () => {
                    const ctx = canvas.getContext("2d");
                    const detections = await faceapi
                        .detectAllFaces(video, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.6 }))
                        .withFaceLandmarks()
                        .withFaceDescriptors();
                    const resizedDetections = faceapi.resizeResults(detections, displaySize);
                    ctx.clearRect(0, 0, canvas.width, canvas.height);

                    boxes = resizedDetections.map((d) => {
                        const result = faceMatcher.findBestMatch(d.descriptor);
                        const labelResult = result.distance > 0.5 ? "Unknown" : result.label;
                        const matchedData = imageData.find(img => img.label === labelResult);
                        const group = matchedData ? matchedData.group : "Unknown";
                        return { box: d.detection.box, label: labelResult, group };
                    });

                    boxes.forEach(({ box, label, group }) => {
                        let color = "gray";
                        if (group === "Family") color = "green";
                        else if (group === "Neighbors") color = "blue";
                        else if (group === "CareGivers") color = "yellow";
                        else if (label === "Unknown") color = "red";

                        ctx.strokeStyle = color;
                        ctx.lineWidth = 2;
                        ctx.strokeRect(box.x, box.y, box.width, box.height + 30);

                        // **Set Larger Font Size**
                        ctx.font = "bold 14px Arial"; // Change font size here
                        ctx.fillStyle = color;

                        const text = label === "Unknown" ? "Unknown" : `${label} (${group})`;
                        const textWidth = ctx.measureText(text).width;
                        const textHeight = 20; // Adjust if needed

                        // Draw background for text
                        ctx.fillRect(box.x, box.y - textHeight, textWidth + 10, textHeight);

                        // Draw text
                        ctx.fillStyle = "white";
                        ctx.fillText(text, box.x + 5, box.y - 5);
                    });
                }, 100);

                canvas.addEventListener("click", (event) => {
                    const rect = canvas.getBoundingClientRect();
                    const clickX = event.clientX - rect.left;
                    const clickY = event.clientY - rect.top;
                    const ctx = canvas.getContext("2d");

                    for (const { box, label, group } of boxes) {
                        if (
                            clickX >= box.x &&
                            clickX <= box.x + box.width &&
                            clickY >= box.y &&
                            clickY <= box.y + box.height
                        ) {
                            console.log(`Clicked on: ${label} (${group})`);

                            //window.parent.bubble_fn_sendLabelToBubble(label);


                            // Click effect: flash the inside of the rectangle in gray
                            ctx.fillStyle = "rgba(128, 128, 128, 0.5)";
                            ctx.fillRect(box.x, box.y, box.width, box.height + 30);
                            setTimeout(() => {
                                ctx.clearRect(box.x, box.y, box.width, box.height);
                            }, 200);
                            return;
                        }
                    }
                });
            });


        });
    </script>
</body>